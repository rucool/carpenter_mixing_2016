{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0aad8-d684-475b-a0d0-2c90a58dc1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from model1_functions import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77447867-09d4-493d-991d-59e66a4e1be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pper = ['setup','peak','breakdown']\n",
    "#initial profiles csv for set up peak and breakdown based on glider profiles\n",
    "#these intial profiles are 25m\n",
    "init_profs = pd.read_csv('../Model 1/carp_pea_init_profs.csv')\n",
    "\n",
    "res_df = None #initialize none to concat result dataframe to for each period\n",
    "extend = False\n",
    "dmax_extend = 40 #depth you want profile extended to\n",
    "dz = 0.25\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ii,per in enumerate(pper):\n",
    "    print(per)\n",
    "    init_df = init_profs[init_profs.per==per]\n",
    "    # if we want this extended to 40m\n",
    "    if extend == True:\n",
    "        dmin_extend = init_df['z'].iloc[-1].astype(int)+dz\n",
    "        z_extend = np.arange(dmin_extend,dmax_extend+dz,dz)\n",
    "        dens_extend = [init_df['dens'].iloc[-1]]*len(z_extend)\n",
    "        mldL_extend = [init_df['mldL'].iloc[-1]]*len(z_extend)\n",
    "        mldU_extend = [init_df['mldU'].iloc[-1]]*len(z_extend)\n",
    "        p_thick_extend = [init_df['p_thick'].iloc[-1]]*len(z_extend)\n",
    "        pea_extend = [init_df['pea'].iloc[-1]]*len(z_extend)\n",
    "        per_extend = [init_df['per'].iloc[-1]]*len(z_extend)\n",
    "        extend_df = pd.DataFrame({'z':z_extend,'dens':dens_extend,'mldU':mldU_extend,'mldL':mldL_extend,'p_thick':p_thick_extend,'pea':pea_extend,'per':per_extend})\n",
    "\n",
    "        init_df = pd.concat([init_df,extend_df],ignore_index=True)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    ## model\n",
    "\n",
    "    datasave_Pstr_H=[]\n",
    "    datasave_Pstr_L=[]\n",
    "    datasave_L_D = []\n",
    "    datasave_H_D = []\n",
    "\n",
    "    #params from initial compisite profiles\n",
    "    H = init_df['z'].iloc[-1].astype(int)\n",
    "\n",
    "\n",
    "    dens = init_df['dens'].values\n",
    "    mldU_g = init_df['mldU'].iloc[0].astype(int)\n",
    "    mldL_g = init_df['mldL'].iloc[0].astype(int)\n",
    "\n",
    "    #change to z up positive like carpenter\n",
    "    z = np.flipud(init_df['z'].values)\n",
    "    mldL_c = H-mldL_g\n",
    "    mldU_c = H-mldU_g\n",
    "\n",
    "    b=mldU_c-mldL_c #pycnocline thickness\n",
    "    h = (mldU_c+mldL_c)/2 #height off bottom to center of pycnocline\n",
    "    \n",
    "    \n",
    "\n",
    "    rho_s = init_df['dens'].iloc[0].astype(int) #surface dens\n",
    "    rho_b = init_df['dens'].iloc[-1].astype(int) #bottom dens\n",
    "\n",
    "    \n",
    "    #params replicated from Carpenter et al., 2016\n",
    "    CDL = 0.35          # Low Drag Coefficient (dimensionless)\n",
    "    CDH = 1.0           # High Drage Coefficient (dimensionless)\n",
    "\n",
    "    D = 11.28           # Diameter of Monopile Turbine foundation (m)\n",
    "    l = 1000            # Turbine Spaceing (m)\n",
    "\n",
    "    rho0 =1026 #np.trapz(dens,dx=dz,axis=0)/H #1026 #Reference Ocean Density (kg/m^3)\n",
    "    g = 9.81            # Acceleration Due to Gravity (m/s^2)\n",
    "    Rif = 0.17  #flux richardson number\n",
    "\n",
    "    # Calculate Phi (kj/m2)\n",
    "    phi = phi_carpenter(dens,z,dz,H)\n",
    "    phi = phi*1000 #bring back to SI units for Pstr calculation\n",
    "\n",
    "    \n",
    "    #range of current velocities covering tidal to storm driven magnitudes\n",
    "    u = np.arange(0.01,0.81,0.01)\n",
    "    for uu in u:\n",
    "        uu = np.round(uu,1)\n",
    "        print(uu)\n",
    "        Pstr_L, Pstr_H = Pstr (CDL,CDH,D,l,rho0,uu,H)\n",
    "        datasave_Pstr_L.append(Pstr_L)\n",
    "        datasave_Pstr_H.append(Pstr_H)\n",
    "        tau_mix_L = Tau_mix_L (phi,H,Rif,Pstr_L,b)\n",
    "        tau_mix_H = Tau_mix_H (phi,H,Rif,Pstr_H,b)\n",
    "        datasave_L_D.append(tau_mix_L)\n",
    "        datasave_H_D.append(tau_mix_H)\n",
    "\n",
    "    data = {\n",
    "        'Current Velocity': u,\n",
    "        'Pstr CD = 0.35': datasave_Pstr_L,\n",
    "        'Pstr CD = 1.0': datasave_Pstr_H,\n",
    "        'Tmix CD = 0.35': datasave_L_D,\n",
    "        'Tmix CD 1.0': datasave_H_D,\n",
    "        'h':[h]*len(u),\n",
    "        'per':[per]*len(u)\n",
    "    }\n",
    "    #create and concat all dataframes into res_df\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    if res_df is None:\n",
    "        res_df = df\n",
    "    else:\n",
    "        res_df = pd.concat([res_df,df])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4433b1e-ac51-42c7-9187-3c83f2d22066",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_results(res_df,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f015c45-2218-4655-8b8f-64c921d8d778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
