{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4225ac44-be47-473d-a1b4-30842cd940a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!git clone https://github.com/rucool/carpenter_mixing_2016.git\n",
    "\n",
    "# Get the path to the cloned repository\n",
    "repo_path = os.path.join('/content', 'carpenter_mixing_2016', 'Model2')\n",
    "\n",
    "# Add the repository path to sys.path\n",
    "sys.path.append(repo_path)\n",
    "print(repo_path)\n",
    "# Import the functions\n",
    "from model2_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ed3cd-8f79-4776-aa77-517f6acf2c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pper = ['setup','peak','breakdown']\n",
    "#initial profiles csv for set up peak and breakdown based on glider profiles\n",
    "#these intial profiles are 25m\n",
    "init_profs = pd.read_csv('https://raw.githubusercontent.com/rucool/carpenter_mixing_2016/7b446192e5fe633f36e149ab98ee3d876e929e44/Glider_Data/carp_pea_init_profs.csv')\n",
    "res_df =None #initialize none to concat result dataframe to for each period\n",
    "\n",
    "\n",
    "for ii,per in enumerate(pper):\n",
    "    print(per)\n",
    "    init_df = init_profs[init_profs.per==per]\n",
    "    dz=0.25\n",
    "    extend=False\n",
    "    dmax_extend=40 #depth you want profile extended to\n",
    "    if extend == True:\n",
    "        # if we want this extended to 40m\n",
    "        \n",
    "        dmin_extend = init_df['z'].iloc[-1].astype(int)+dz\n",
    "        z_extend = np.arange(dmin_extend,dmax_extend+dz,dz)\n",
    "        dens_extend = [init_df['dens'].iloc[-1]]*len(z_extend)\n",
    "        mldL_extend = [init_df['mldL'].iloc[-1]]*len(z_extend)\n",
    "        mldU_extend = [init_df['mldU'].iloc[-1]]*len(z_extend)\n",
    "        p_thick_extend = [init_df['p_thick'].iloc[-1]]*len(z_extend)\n",
    "        pea_extend = [init_df['pea'].iloc[-1]]*len(z_extend)\n",
    "        per_extend = [init_df['per'].iloc[-1]]*len(z_extend)\n",
    "        extend_df = pd.DataFrame({'z':z_extend,'dens':dens_extend,'mldU':mldU_extend,'mldL':mldL_extend,'p_thick':p_thick_extend,'pea':pea_extend,'per':per_extend})\n",
    "\n",
    "        init_df = pd.concat([init_df,extend_df],ignore_index=True)\n",
    "\n",
    "    ## model\n",
    "    \n",
    "    datasave_Pstr_H=[]\n",
    "    datasave_Pstr_L=[]\n",
    "    datasave_L_D = []\n",
    "    datasave_H_D = []\n",
    "\n",
    "    #params from initial compisite profiles\n",
    "    H = init_df['z'].iloc[-1].astype(int)\n",
    "\n",
    "\n",
    "    dens = init_df['dens'].values\n",
    "    mldU_g = init_df['mldU'].iloc[0].astype(int)\n",
    "    mldL_g = init_df['mldL'].iloc[0].astype(int)\n",
    "\n",
    "    #change to z up positive like carpenter\n",
    "    z = np.flipud(init_df['z'].values)\n",
    "    mldL_c = H-mldL_g\n",
    "    mldU_c = H-mldU_g\n",
    "\n",
    "    lidx=np.where(z==mldL_c)\n",
    "    uidx=np.where(z==mldU_c)\n",
    "    \n",
    "    delta_rho = dens[-1]-dens[0]\n",
    "\n",
    "\n",
    "\n",
    "    CDL = 0.35          # Low Drag Coefficient (dimensionless)\n",
    "    CDH = 1.0           # High Drage Coefficient (dimensionless)\n",
    "\n",
    "    D = 11.28           # Diameter of Monopile Turbine foundation (m)\n",
    "    l = 1000            # Turbine Spaceing (m)\n",
    "\n",
    "    \n",
    "    rho0 =1026 #np.trapz(dens,dx=dz,axis=0)/H #1026 #Reference Ocean Density (kg/m^3)\n",
    "    g = 9.81            # Acceleration Due to Gravity (m/s^2)\n",
    "    Rif = 0.17  #flux richardson number\n",
    "\n",
    "    u = np.arange(0.01,0.81,0.01)\n",
    "    \n",
    "    for uu in u:\n",
    "        uu = np.round(uu,3)\n",
    "        print(uu)\n",
    "        Pstr_L, Pstr_H = Pstr (CDL,CDH,D,l,rho0,uu,H)\n",
    "        datasave_Pstr_L.append(Pstr_L)\n",
    "        datasave_Pstr_H.append(Pstr_H)\n",
    "        # Rate of change of pycnocline thickness over time (m/s)\n",
    "        # dbdt = (2 * np.pi * Rif * P_str) / (g * delta_rho * H)  # [m/s]\n",
    "        dbdt_L,dbdt_H = dbdt(Rif, Pstr_L, Pstr_H, g, delta_rho, H)\n",
    "        # Mixing time scale based on unsteady model (s)\n",
    "        t_mix_days_H, t_mix_days_L = t_mix_days(H,dbdt_L,dbdt_H)\n",
    "        datasave_L_D.append(t_mix_days_L)\n",
    "        datasave_H_D.append(t_mix_days_H)\n",
    "\n",
    "    data = {\n",
    "    'Current Velocity': u,\n",
    "    'Pstr CD = 0.35': datasave_Pstr_L,\n",
    "    'Pstr CD = 1.0': datasave_Pstr_H,\n",
    "    'Tmix CD = 0.35': datasave_L_D,\n",
    "    'Tmix CD 1.0': datasave_H_D,\n",
    "    'per':[per]*len(u)}\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    if res_df is None:\n",
    "        res_df = df\n",
    "    else:\n",
    "        res_df = pd.concat([res_df,df])\n",
    "    res_df.to_csv('./all_results_H'+str(H)+'model2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedfd5f3-3889-41c6-8a19-4934130c9d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_results(res_df,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7529c0-e518-4d86-af41-b34383afdd69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
